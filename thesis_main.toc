\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Overview of CutLer}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}Contribution and Key Insights}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Outline}{3}{section.1.4}%
\contentsline {chapter}{\numberline {2}Related Work}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Self-supervised feature learning}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Contrastive learning}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Clustering-based feature learning}{5}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Distillation-based methods}{6}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Unsupervised object detection and instance segmentation}{6}{section.2.2}%
\contentsline {section}{\numberline {2.3}Semi-supervised object detection and instance segmentation}{7}{section.2.3}%
\contentsline {chapter}{\numberline {3}Background}{9}{chapter.3}%
\contentsline {section}{\numberline {3.1}Vision Transformer}{9}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Patch Tokens and Positional Encoding}{9}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Transformer Encoder}{10}{subsection.3.1.2}%
\contentsline {subsubsection}{\nonumberline Multi-Head Self-Attention (MSA)}{10}{subsubsection*.11}%
\contentsline {subsubsection}{\nonumberline Layer Normalization and Residual Connections}{12}{subsubsection*.13}%
\contentsline {subsubsection}{\nonumberline Output Layer}{12}{subsubsection*.15}%
\contentsline {section}{\numberline {3.2}DINO}{12}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Knowledge distillation}{12}{subsection.3.2.1}%
\contentsline {subsubsection}{\nonumberline Momentum Encoder for Teacher}{13}{subsubsection*.18}%
\contentsline {subsection}{\numberline {3.2.2}Training Process}{14}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}CutLer}{14}{section.3.3}%
\contentsline {chapter}{\numberline {4}Approach}{15}{chapter.4}%
\contentsline {section}{\numberline {4.1}Comparison of similarity/distance measures in discriminating object class}{15}{section.4.1}%
\contentsline {section}{\numberline {4.2}Relaxed best buddies}{18}{section.4.2}%
\contentsline {section}{\numberline {4.3}Input data}{18}{section.4.3}%
\contentsline {subsubsection}{\nonumberline Image}{18}{subsubsection*.23}%
\contentsline {subsubsection}{\nonumberline Text}{19}{subsubsection*.25}%
\contentsline {section}{\numberline {4.4}Vision Encoder}{19}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Transformer Layer}{20}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Grouping Block}{20}{subsection.4.4.2}%
\contentsline {subsubsection}{\nonumberline Attention}{20}{subsubsection*.27}%
\contentsline {subsubsection}{\nonumberline Assignment}{21}{subsubsection*.29}%
\contentsline {subsection}{\numberline {4.4.3}Multi-stage Information Flow}{21}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}Text Encoder}{23}{subsection.4.4.4}%
\contentsline {section}{\numberline {4.5}Training Loss}{23}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Contrastive loss}{23}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}Multi-label Contrastive Loss}{25}{subsection.4.5.2}%
\contentsline {section}{\numberline {4.6}Inference}{26}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Class Descriptive Prompts}{26}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}Image and Text Alignment}{26}{subsection.4.6.2}%
\contentsline {subsubsection}{\nonumberline Affinity Metric between Segments and Classes}{26}{subsubsection*.34}%
\contentsline {subsubsection}{\nonumberline Average Affinity Metric}{28}{subsubsection*.36}%
\contentsline {subsubsection}{\nonumberline Selection of Top-5 Classes}{28}{subsubsection*.38}%
\contentsline {subsection}{\numberline {4.6.3}Global Attention}{29}{subsection.4.6.3}%
\contentsline {subsection}{\numberline {4.6.4}Integration of Grouping and Labelling}{29}{subsection.4.6.4}%
\contentsline {section}{\numberline {4.7}Entropy Regularization}{30}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Entropy of Patches over Groups}{30}{subsection.4.7.1}%
\contentsline {subsection}{\numberline {4.7.2}Entropy of Patches over Labels}{31}{subsection.4.7.2}%
\contentsline {subsection}{\numberline {4.7.3}Entropy over Segment Affinity Metric}{33}{subsection.4.7.3}%
\contentsline {chapter}{\numberline {5}Experiments and Results}{35}{chapter.5}%
\contentsline {section}{\numberline {5.1}Dataset}{35}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}COCO}{35}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}PASCAL VOC }{36}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}PASCAL Context }{36}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}ADE 20K }{36}{subsection.5.1.4}%
\contentsline {section}{\numberline {5.2}Evaluation Metric}{36}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Mean Intersection Over Union }{36}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Experiment Setting}{37}{section.5.3}%
\contentsline {section}{\numberline {5.4}Visual Grouping vs Visual-Text Alignment}{38}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Analysis of Visual Grouping}{38}{subsection.5.4.1}%
\contentsline {subsubsection}{\nonumberline Feature Extraction}{38}{subsubsection*.45}%
\contentsline {subsubsection}{\nonumberline Soft Label Assignment}{39}{subsubsection*.47}%
\contentsline {subsubsection}{\nonumberline Find K-Nearest Neighbors (KNN)}{39}{subsubsection*.49}%
\contentsline {subsubsection}{\nonumberline Evaluation}{40}{subsubsection*.51}%
\contentsline {subsection}{\numberline {5.4.2}Analysis of Vision-Text Alignment}{40}{subsection.5.4.2}%
\contentsline {section}{\numberline {5.5}Fine-tuning the Pretrained Model}{43}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Choice of Components}{43}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Choice of Batch Size}{43}{subsection.5.5.2}%
\contentsline {section}{\numberline {5.6}Exploring Impact of Multi-label}{45}{section.5.6}%
\contentsline {section}{\numberline {5.7}Refinement in Label Extraction}{45}{section.5.7}%
\contentsline {subsection}{\numberline {5.7.1}Extract Labels with Most Frequent Entities}{47}{subsection.5.7.1}%
\contentsline {section}{\numberline {5.8}Entropy Regularization}{48}{section.5.8}%
\contentsline {section}{\numberline {5.9}Fine-tuning on High Resolution}{50}{section.5.9}%
\contentsline {subsection}{\numberline {5.9.1}High Resolution Complements Entropy Regularization}{50}{subsection.5.9.1}%
\contentsline {section}{\numberline {5.10}Non-noisy Contrastive Loss}{52}{section.5.10}%
\contentsline {section}{\numberline {5.11}Impact of Inference Settings}{55}{section.5.11}%
\contentsline {section}{\numberline {5.12}Analysis of The Baseline}{55}{section.5.12}%
\contentsline {subsection}{\numberline {5.12.1}Visualization of IoU Disparity}{55}{subsection.5.12.1}%
\contentsline {subsection}{\numberline {5.12.2}Visualization of Representation Space}{58}{subsection.5.12.2}%
\contentsline {section}{\numberline {5.13}Exploring Number of Stages in Visual Encoder}{59}{section.5.13}%
\contentsline {subsection}{\numberline {5.13.1}Single Grouping Block}{62}{subsection.5.13.1}%
\contentsline {subsection}{\numberline {5.13.2}Three Grouping Blocks}{62}{subsection.5.13.2}%
\contentsline {section}{\numberline {5.14}DINO Features}{64}{section.5.14}%
\contentsline {subsection}{\numberline {5.14.1}Feature Affinity Metric}{64}{subsection.5.14.1}%
\contentsline {subsection}{\numberline {5.14.2}Integration of DINO Features in GroupViT}{65}{subsection.5.14.2}%
\contentsline {subsection}{\numberline {5.14.3}Distillation of Information from DINO to GroupViT}{65}{subsection.5.14.3}%
\contentsline {section}{\numberline {5.15}Visualization of Curves}{67}{section.5.15}%
\contentsline {section}{\numberline {5.16}Qualitative Analysis}{68}{section.5.16}%
\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{73}{chapter.6}%
\contentsline {section}{\numberline {6.1}Future Work}{73}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Integration of DINO Features: Synergizing Strengths}{74}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Enriching Negative Sample Pool for Noise-Free Contrastive Loss}{74}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Exploring Hierarchical Grouping with Web-Scaled Data}{74}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Training with Datasets Including Stuff Classes}{74}{subsection.6.1.4}%
\contentsline {chapter}{\numberline {7}Acknowledgments}{75}{chapter.7}%
\contentsline {chapter}{Bibliography}{76}{chapter.7}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
