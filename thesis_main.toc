\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Motivation}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Overview of CutLer}{1}{section.1.2}%
\contentsline {section}{\numberline {1.3}Contribution and Key Insights}{2}{section.1.3}%
\contentsline {section}{\numberline {1.4}Outline}{3}{section.1.4}%
\contentsline {chapter}{\numberline {2}Related Work}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Self-supervised feature learning}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Contrastive learning}{5}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Clustering-based feature learning}{5}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Distillation-based methods}{6}{subsection.2.1.3}%
\contentsline {section}{\numberline {2.2}Unsupervised object detection and instance segmentation}{6}{section.2.2}%
\contentsline {section}{\numberline {2.3}Semi-supervised object detection and instance segmentation}{7}{section.2.3}%
\contentsline {chapter}{\numberline {3}Background}{9}{chapter.3}%
\contentsline {section}{\numberline {3.1}Vision Transformer}{9}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Patch Tokens and Positional Encoding}{9}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Transformer Encoder}{10}{subsection.3.1.2}%
\contentsline {subsubsection}{\nonumberline Multi-Head Self-Attention (MSA)}{10}{subsubsection*.11}%
\contentsline {subsubsection}{\nonumberline Layer Normalization and Residual Connections}{12}{subsubsection*.13}%
\contentsline {subsubsection}{\nonumberline Output Layer}{12}{subsubsection*.15}%
\contentsline {section}{\numberline {3.2}DINO}{12}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Knowledge distillation}{12}{subsection.3.2.1}%
\contentsline {subsubsection}{\nonumberline Momentum Encoder for Teacher}{13}{subsubsection*.18}%
\contentsline {subsection}{\numberline {3.2.2}Training Process}{14}{subsection.3.2.2}%
\contentsline {section}{\numberline {3.3}CutLer}{14}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Maskcut}{14}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Droploss}{16}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Self-Training}{17}{subsection.3.3.3}%
\contentsline {chapter}{\numberline {4}Approach}{19}{chapter.4}%
\contentsline {section}{\numberline {4.1}Comparison of similarity/distance measures in discriminating object class}{19}{section.4.1}%
\contentsline {section}{\numberline {4.2}Relaxed best buddies}{22}{section.4.2}%
\contentsline {section}{\numberline {4.3}Input data}{22}{section.4.3}%
\contentsline {subsubsection}{\nonumberline Image}{22}{subsubsection*.25}%
\contentsline {subsubsection}{\nonumberline Text}{23}{subsubsection*.27}%
\contentsline {section}{\numberline {4.4}Vision Encoder}{23}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Transformer Layer}{24}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Grouping Block}{24}{subsection.4.4.2}%
\contentsline {subsubsection}{\nonumberline Attention}{24}{subsubsection*.29}%
\contentsline {subsubsection}{\nonumberline Assignment}{25}{subsubsection*.31}%
\contentsline {subsection}{\numberline {4.4.3}Multi-stage Information Flow}{25}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}Text Encoder}{27}{subsection.4.4.4}%
\contentsline {section}{\numberline {4.5}Training Loss}{27}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Contrastive loss}{27}{subsection.4.5.1}%
\contentsline {subsection}{\numberline {4.5.2}Multi-label Contrastive Loss}{29}{subsection.4.5.2}%
\contentsline {section}{\numberline {4.6}Inference}{30}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Class Descriptive Prompts}{30}{subsection.4.6.1}%
\contentsline {subsection}{\numberline {4.6.2}Image and Text Alignment}{30}{subsection.4.6.2}%
\contentsline {subsubsection}{\nonumberline Affinity Metric between Segments and Classes}{30}{subsubsection*.36}%
\contentsline {subsubsection}{\nonumberline Average Affinity Metric}{32}{subsubsection*.38}%
\contentsline {subsubsection}{\nonumberline Selection of Top-5 Classes}{32}{subsubsection*.40}%
\contentsline {subsection}{\numberline {4.6.3}Global Attention}{33}{subsection.4.6.3}%
\contentsline {subsection}{\numberline {4.6.4}Integration of Grouping and Labelling}{33}{subsection.4.6.4}%
\contentsline {section}{\numberline {4.7}Entropy Regularization}{34}{section.4.7}%
\contentsline {subsection}{\numberline {4.7.1}Entropy of Patches over Groups}{34}{subsection.4.7.1}%
\contentsline {subsection}{\numberline {4.7.2}Entropy of Patches over Labels}{35}{subsection.4.7.2}%
\contentsline {subsection}{\numberline {4.7.3}Entropy over Segment Affinity Metric}{37}{subsection.4.7.3}%
\contentsline {chapter}{\numberline {5}Experiments and Results}{39}{chapter.5}%
\contentsline {section}{\numberline {5.1}Dataset}{39}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}COCO}{39}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}PASCAL VOC }{40}{subsection.5.1.2}%
\contentsline {subsection}{\numberline {5.1.3}PASCAL Context }{40}{subsection.5.1.3}%
\contentsline {subsection}{\numberline {5.1.4}ADE 20K }{40}{subsection.5.1.4}%
\contentsline {section}{\numberline {5.2}Evaluation Metric}{40}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Mean Intersection Over Union }{40}{subsection.5.2.1}%
\contentsline {section}{\numberline {5.3}Experiment Setting}{41}{section.5.3}%
\contentsline {section}{\numberline {5.4}Visual Grouping vs Visual-Text Alignment}{42}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Analysis of Visual Grouping}{42}{subsection.5.4.1}%
\contentsline {subsubsection}{\nonumberline Feature Extraction}{42}{subsubsection*.47}%
\contentsline {subsubsection}{\nonumberline Soft Label Assignment}{43}{subsubsection*.49}%
\contentsline {subsubsection}{\nonumberline Find K-Nearest Neighbors (KNN)}{43}{subsubsection*.51}%
\contentsline {subsubsection}{\nonumberline Evaluation}{44}{subsubsection*.53}%
\contentsline {subsection}{\numberline {5.4.2}Analysis of Vision-Text Alignment}{44}{subsection.5.4.2}%
\contentsline {section}{\numberline {5.5}Fine-tuning the Pretrained Model}{47}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Choice of Components}{47}{subsection.5.5.1}%
\contentsline {subsection}{\numberline {5.5.2}Choice of Batch Size}{47}{subsection.5.5.2}%
\contentsline {section}{\numberline {5.6}Exploring Impact of Multi-label}{49}{section.5.6}%
\contentsline {section}{\numberline {5.7}Refinement in Label Extraction}{49}{section.5.7}%
\contentsline {subsection}{\numberline {5.7.1}Extract Labels with Most Frequent Entities}{51}{subsection.5.7.1}%
\contentsline {section}{\numberline {5.8}Entropy Regularization}{52}{section.5.8}%
\contentsline {section}{\numberline {5.9}Fine-tuning on High Resolution}{54}{section.5.9}%
\contentsline {subsection}{\numberline {5.9.1}High Resolution Complements Entropy Regularization}{54}{subsection.5.9.1}%
\contentsline {section}{\numberline {5.10}Non-noisy Contrastive Loss}{56}{section.5.10}%
\contentsline {section}{\numberline {5.11}Impact of Inference Settings}{59}{section.5.11}%
\contentsline {section}{\numberline {5.12}Analysis of The Baseline}{59}{section.5.12}%
\contentsline {subsection}{\numberline {5.12.1}Visualization of IoU Disparity}{59}{subsection.5.12.1}%
\contentsline {subsection}{\numberline {5.12.2}Visualization of Representation Space}{62}{subsection.5.12.2}%
\contentsline {section}{\numberline {5.13}Exploring Number of Stages in Visual Encoder}{63}{section.5.13}%
\contentsline {subsection}{\numberline {5.13.1}Single Grouping Block}{66}{subsection.5.13.1}%
\contentsline {subsection}{\numberline {5.13.2}Three Grouping Blocks}{66}{subsection.5.13.2}%
\contentsline {section}{\numberline {5.14}DINO Features}{68}{section.5.14}%
\contentsline {subsection}{\numberline {5.14.1}Feature Affinity Metric}{68}{subsection.5.14.1}%
\contentsline {subsection}{\numberline {5.14.2}Integration of DINO Features in GroupViT}{69}{subsection.5.14.2}%
\contentsline {subsection}{\numberline {5.14.3}Distillation of Information from DINO to GroupViT}{69}{subsection.5.14.3}%
\contentsline {section}{\numberline {5.15}Visualization of Curves}{71}{section.5.15}%
\contentsline {section}{\numberline {5.16}Qualitative Analysis}{72}{section.5.16}%
\contentsline {chapter}{\numberline {6}Conclusion and Future Work}{77}{chapter.6}%
\contentsline {section}{\numberline {6.1}Future Work}{77}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Integration of DINO Features: Synergizing Strengths}{78}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Enriching Negative Sample Pool for Noise-Free Contrastive Loss}{78}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Exploring Hierarchical Grouping with Web-Scaled Data}{78}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Training with Datasets Including Stuff Classes}{78}{subsection.6.1.4}%
\contentsline {chapter}{\numberline {7}Acknowledgments}{79}{chapter.7}%
\contentsline {chapter}{Bibliography}{80}{chapter.7}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
