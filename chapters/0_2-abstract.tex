\chapter*{Abstract}
%In the evolving realm of deep learning for scene understanding, the traditional dichotomy between grouping and recognition has blurred, thanks to integrated end-to-end training systems. Yet, GroupViT reshapes this landscape by reintroducing explicit grouping in deep networks. This novel bottom-up approach rekindles the essence of semantic segmentation in contrasts with traditional top-down methods. GroupViT, trained on weak supervisory signals from text, showcases impressive results across various datasets, highlighting its efficacy for open-vocabulary segmentation. 
%% By identifying and grouping coherent concepts before labeling, GroupViT remarkably aligns segmentation performance with human perception. 
%
%
%Within this thesis, we undertake a dissection of the pretrained GroupViT model, isolating two pivotal components for open-vocabulary segmentation: Visual Grouping and Vision-Text Alignment. Based on our analysis, it becomes evident that there is substantial room for improvement, particularly in Visual Grouping. By leveraging GroupViTâ€™s pretrained model and further training on a cleaner, smaller MSCOCO dataset, we observed promising enhancements on the dataset. However, there are trade-offs, compromising performance on downstream dataset such as PASCAL VOC and PASCAL Context.
%% By capitalizing on GroupViT's existing knowledge and training the relevant components on cleaner and smaaler MSCOCO dataset, promising enhancements emerge on the validation split. However, these gains come with trade-offs, as performance on downstream datasets is compromised.
%
%To address these challenges, this work introduces strategic enhancements. First, we incorporate entropy regularization techniques to improve semantic grouping and visual-text alignment. Second, we propose a non-noisy contrastive loss, countering limitations of training on a smaller dataset and leading to more robust, accurate results.
%% To tackle these challenges, the dissertation introduces strategic enhancements. One of these enhancements involves the incorporation of entropy regularization techniques. By implementing these techniques, the dissertation seeks to improve the process of grouping semantic concepts and aligning visual and textual elements more effectively. Another significant enhancement proposed is the adoption of a non-noisy contrastive loss. This approach addresses the inherent limitations associated with training on a smaller dataset, ultimately leading to more robust and accurate results.
%
%These systematic refinements furnish a framework to further train the pretrained model of  GroupViT on smaller and cleaner datasets for segmentation, while upholding the performance across datasets.
%% By methodically implementing these refinements, the dissertation provides a robust framework for fine-tuning a pretrained GroupViT model on a more streamlined datasets, preserving performance standards across downstream applications.
%% Deviating from Biological vision, Deep learning netwroks have blurred the distinction between between grouping and  recognition following the top-down approach. This Thesis explores and enhances GroupViT that approached semantic segmentation like HUmans, by finding and grouping coherent concepts and finaaly label them in a bottom-up manner. This results in fucntioning of segmentation closer to humar perception. GroupViT training on weak supervisory signals of text achieves remarkable performance on many downstream datasets making it suitable for open-vocabulary segmentation.
%
%
%%  In this Thesis, we examine the pretrained model of GroupViT by decoupling teo of its major components for the task of open-vocabulary segmentation called Visual Grouping and Vision-Text alignment and examining them indivisually. We found that although both of them have some room of improvement, Visual Grouping has a bigger one . While utilizing the pretrained knowledge of GroupViT , training relevant components on a cleaner, smaller dataset of MSCOCO, we observed improved performance on the validation split of training dataset but big comprise on downstream datasets. We proceeded with making targetted improvements (i) Firstly we proposes entropy regularization methods to improved grouping of cohesive concepts and improve visual-text alignment (ii) We propose non-noisy contrastive loss due to training on smaller datasets.
%
%%  This strategic and step-wise improvement provides an effective recipe to train a pretrained model of GroupViT on a cleaner smaller dataset without comprising its performance on downstream datasets
%
%% I am further investigating the potential of GroupVIT on cleaner, smaller but more challenging datasets such as COCO. GroupViT combines a hierarchical grouping architecture with VIT to achieve semantic segmentation using only text supervision. The grouping mechanism of GroupVIT learns to group similar image regions for segmentation by comparing segment-level embeddings to those derived from captions through contrastive learning. As part of our current roadmap, we plan to explore a new localized paired loss, which will aim to align grouped image segments with specific words or pairs of words in the text caption at different levels of grouping hierarchy. GroupVIT currently uses a multi-label contrastive loss that aims to align emerged grouped segments with entire captions. However, we believe that localizing the loss to the parts of the caption that represent the emerged grouped segments could improve the performance of GroupVIT by targetting localized semantic similarity. In addition, we will investigate different levels of hierarchy to explore the efficiency of the model.